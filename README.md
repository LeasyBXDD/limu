# 听课记录

## 04 数据操作 + 数据预处理

N位数组样例

标量

向量

矩阵

3d 一张RGB的图片 （宽度、高度、通道）

4d 一个RGB图片的批量（批量、宽度、高度、通道）

5d 一个视频批量（时间、批量、宽度、高度、通道）

创建数组

访问元素

数据操作

导入 torch

reshape修改张量的形状

zeros ones 

创建数组后可以使用标准的算数运算

也可以把多个张量连接在一起

逻辑运算符 构建二元张量

广播机制（最容易出错的地方）

id 内存 指针

数据预处理实现

如果有一个原始数据，怎么读取用于之后进行处理

创建一个人工数据集，存储在csv（逗号分隔值）文件中

从创建的csv文件中加载原始数据集 使用pandas

read_csv

为了处理缺失的数据：删除、插值

将NaN视为一个类别

## 05 线性代数

 标量由只有一个元素的张量表示

将向量视为标量值组成的列表

通过张量的索引来访问任意元素

访问张量的长度

只有一个轴的张量，形状只有一个元素

通过指定两个分量m和n来小黄见一个形状位mxn的矩阵

矩阵的转置

对称矩阵

转置等于自己

就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建由更多轴的数据结构

两个矩阵的按元素乘法称为 哈达玛积

计算其元素的和

表示任意形状的张量的元素和

指定求和汇总张量的值

一个与求和相关的量是 平均值

计算总和

点积是相同位置的暗元素成绩的和

我i们可以他用过执行暗元素乘法

矩阵向量机是一个长度位m的裂像力啊ing，

我们可以将矩阵矩阵乘法看作是简单的执行m次矩阵向量机，并将

L2范数 是向量元素平法和的平方根

norm

L1范数 表示位向量元素的

矩阵的 F范数 矩阵元素的平方和的平方根

按特定轴求和

假设有个矩阵 5行4列

shape: [5,4]

axis: 0, 1

## 矩阵计算

标量导数

导数是切线的斜率

将导数扩展到不可微的函数

亚导数

梯度

将导数拓展到向量

注意形状

分子布局符号（一般使用）

分母布局符号

## 自动求导

向量链式法则

标量链式法则

拓展到向量

将代码分解成操作子

将在计算表示成一个无环图

显示构造

隐式构造

自动求导的两种模式

链式法则

正向累计

反向了累计、又称反向传递

求梯度的结果需要一直存储下来，导致对GPU的内存要求大

arange

需要一个地方存储梯度

requires_grad_(True)

dot 内积

通过调用反向传播函数来计算y关于x每个分量的梯度

计算x的另一个函数

默认情况下，Pytorch会累计梯度，我们需要清楚之前的值

在深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和

对标量求导。一般的

将某些计算移动到记录的计算图以外

隐式构造 和 显示构造

需要正向和反向都算一遍

为什么Pytorch会默认累计梯度？是因为Pytorch对内存的管理不是那么好

为什么深度学习都是对标量求导？而不是矩阵或者向量？因为loss通常是标量

求导过程 图结构

 ## 线性回归 + 基础优化算法

在美国买房

衡量预估质量

真实值减去估计值的平方 平方误差

训练数据

权重和偏差

采集数据

训练数据

越多越好

假设我们有n个样本

训练损失

最小化损失来学习参数

线性回归是对n维输入的加权，外加偏差

使用平方损失来衡量预测值和真实值额

线性回归有显示解

线性回归可以看作是单层的神经网络

基础优化方法

梯度下降

挑选一个初始值（随机）

重复迭代参数

选择学习率

不能太小也不能太大

计算梯度很贵（几乎是最贵的）

选择合适的学习率

在整个训练集上算梯度太贵

对整个损失函数求导

求一次梯度需要对整个样本进行

计算代价很大

近似的办法是所有的样本的损失的平均

随机采样b个样本来近似损失

b是批量大小

太小的话，不适合并行来最大利用计算资源

太大内存消耗增加，浪费计算，例如如果所有的样本都是相同的

梯度下降 通过不断验证发梯度方向更新参数求解

小批量随机梯度下降是深度学习默认的求解方法（最稳定的方法）

两个重要的超参数是批量大小和学习率

线性回归的从零开始实现

首先，我们将从零开始实现整个方法

包括数据流水线，模型、损失函数和小批量随机梯度下降优化器

```python
import random 
import torch
from d2l import torch as d2l
```

根据带有噪声的线性模型构造一个人造数据集

我们使用线性模型参数和早射二哥生成数据集机器标签

定义初始化模型参数

定义模型

定义损失函数：均方误差

定义优化算法：小批量随机梯度下降

训练过程

比较真丝参数和通过训练学到的参数来评估训练的成功度

超参数的选择

线性回归的简介实现

通过使用深度学习框架来简介的实现 线性回归模型 生成数据集

```python
import numpy
```

调用框架中现有等的API来读取数据据

构造一个PyTorch数据迭代器

使用框架定义好的层

初始化模型参数

计算均方误差使用的MSELoss，也称平方L2范数

实例化SGD示例

SGD

训练过程的代码与我们从零开始实现是所作的非常相似

 Google colab

为什么使用平方损失而不是绝对差值？其实区别不大，但是绝对差值是一个不可导的，导数比较难求

损失为什么要求平均？本质上没有关系，数值上是一样的，但是

如何找到合适的学习率？

一定的噪音就像是对小孩不是一直夸夸教育

过拟合和欠拟合的情况下，学习率和批次该如何进行调整？有什么常见的策略？

针对批量大小的数据集进行网络线性

## softmax回归 

其实是一个分类问题

分类

mnist 手写数字识别

imageNet 自然物体分类

1000类的分类问题

将人类蛋白质的显微镜图片分成28类

将恶意软件分成9个类别

判断恶意软件的类型

将评论惊醒分类

回归

分类

有相似

但是不一样
回归是但连续数值的输出

损失函数 与真实值的区别

分类一般有多个输出

三分类就有三个输出

置信度

从回归到多分类

均方损失

类别进行编码

n个类别

使用均方损失训练

最大值最为预测

最大值最为预测

过渡到softmax回归

不关心实际的值

是不是正确类型的置信度大

需要正确类的置信度 大于其他类别的置信度

Δ 需要更质心的识别正确类

关心的是相对值

输出匹配概率 非负 和为1

softmax 属性飞赴

指数 非负

交叉熵

softmax回归是一个多累分类模型

使用softmax操作子得到每一个类的预测置信度

使用交叉熵来衡量预测和标号的区别

损失函数

用来衡量预测值和真实值之间的区别

L2 Loss 均方损失

真实值 - 预测值 平方 除以二（方便求导）

似然函数  高斯分布

梯度：一次函数  穿过远点

导数 决定更新参数

L1 Loss 绝对值损失函数 真实-预测 的绝对值

绿色 似然函数

导数 橙色 常熟

绝对值 函数在0不可导

当预测值与真实值相隔比较远的时候

稳定性好

0点处不可导 有+-1的剧烈的变化

不稳定

梯度相似的力度往原点走

Huber‘s Robust Loss

图像分类数据集

MNIST数据集是图像分类中光放使用的数据集，但作为基准数据集过于简单，我们将使用类似但是更加复杂的数据集 Fashion-MNIST

```python
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import 
```

通过框架中内置的函数将Fashion-MNIST数据集下载并读取到内存中

train=true 下载的是训练数据集

两个可视化数据集的函数

next

读取以小批量数据，大小为 batch_size

num_workers

定义 load_data_fashion_mnist 函数

下载 Fashion-MNIST数据集 然后加载到内存中

数据读取

softmax回归的从零开始实现

```python
import torch
from IPython import display
from d2l
```

将转评每个图像，将他们呢视为长度为784的向量，因为我们的数据集有10个类别，所以网络输出维度为10

定义输入输出的维度

定义我们的权重

高斯随机分布的值

形状 是行数 是列数 计算梯度

偏移 

给定一个矩阵x，我们可以对所有元素进行求和

如果按照维度等于0来求和的话，

实现softmax

将元素变成一个非负数 此外一句概率原理，每行总数为1

实现softmax回归模型

创建一个数据，其中包含2个样本在3个类别的预测概率，使用y作为y_hat中概率的索引

```
y = torch.tensor([0,2])
y_hat = torch.tensor
```

实现交叉熵顿时函数

将预测类别与真实y元素进行比较

我们可以评估在任意模型net的准确度

Accumulator实例中创建了2个变量，用于分别存储正确的预测的数量和预测数量的总数

Softmax 的回归的训练

定义一个在动画中绘制数据的实用程序类

训练函数

小批量随机梯度下降

训练模型10个迭代周期

对图像进行分类预测

预测标签（定义见第三章）

Softmax的简介实现

通过深度学习框架的高级API能够

Softmax 回归的输出层是一个全连接层

Flatten

展平层

Sequential

def init_weights

在交叉熵损失函数中传递未归一化的预测，并同时计算softmax机器对数

调用之前定义的训练函数来信训练模型

## 感知机

给定输入x，权重w，和偏移b，感知机输出：

二分类：-1或1

回归输出实数

Softmax回归输出概率

训练感知机

等价于使用批量大小为1的梯度下降

并使用如下的损失函数

收敛定理

XOR问题



